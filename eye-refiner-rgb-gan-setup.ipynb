{"cells":[{"metadata":{"_uuid":"6445ee895e9322ec7a6c93c1fd4d4c9a7cccf40f"},"cell_type":"markdown","source":"# Overview\nThe notebook implements a simpler version of the model discussed in [Learning from Simulated and Unsupervised Images through Adversarial Training](https://arxiv.org/abs/1612.07828). \n### The initial focus is to \n- load the datasets correctly\n- create the refiner and discriminator models\n- use data augmentation on the real and fake images\n- train for a few epochs\n- use the simpler training approach\n\n### Training\n- Unity Images - $x$\n- Real images $y$\n- Refiner Model $\\mathcal{R}$\n- Discriminator Model $\\mathcal{D}$\n### Training Loop (one epoch)\n1. Improve Generator: minimize $-\\log(\\mathcal{D}(\\mathcal{R}(x)))+||\\mathcal{R}(x)-x||$ by updating parameters in $\\mathcal{R}$\n1. Improve Discriminator: maximize $-\\log(\\mathcal{D}(y)+\\log(1-\\mathcal{D}(\\mathcal{R}(x)))$ by updating parameters in $\\mathcal{D}$"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"%matplotlib inline\nimport os\nimport numpy as np\nimport h5py\nimport matplotlib.pyplot as plt\nimport keras\nimport keras.backend as K\nfrom skimage.util.montage import montage2d\ndata_dir = os.path.join('..', 'input', 'eye-gaze')\nhelen_eye_dir = '../input/getting-all-the-eye-balls/'\nnorm_stack = lambda x: np.clip((x-127.0)/127.0, -1, 1)\ndef norm_stack(x):\n    # calculate statistics on first 20 points\n    mean = np.mean(x[:20])\n    std = np.std(x[:20])\n    return (1.0*x-mean)/(2*std)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"09751ac27ab03e346499dacbbef56d09a2c4ec2e"},"cell_type":"markdown","source":"# Load Real Data"},{"metadata":{"trusted":true,"_uuid":"5817f514002146f49265cedd5d1a72d3dc41bc3d"},"cell_type":"code","source":"# load the data file and extract dimensions\nmontage_rgb = lambda x: np.clip(0.5*np.stack([montage2d(x[..., i]) for i in range(x.shape[-1])], -1)+0.5, 0, 1) \nwith h5py.File(os.path.join(helen_eye_dir,'eye_balls_rgb.h5'),'r') as t_file:\n    real_image_stack = norm_stack(t_file['image'].value)\nplt.imshow(montage_rgb(real_image_stack[0:16, :, :]))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"83b294f1655cc25f787a43678543c8d2e86a9b0f"},"cell_type":"markdown","source":"# Load Synthetic Data\nGenerated using Unity and UnityEyes Tools"},{"metadata":{"trusted":true,"_uuid":"9750b9816f5837261396ad5beb03e76c9e988092"},"cell_type":"code","source":"# load the data file and extract dimensions\nwith h5py.File(os.path.join(data_dir,'gaze.h5'),'r') as t_file:\n    print(list(t_file.keys()))\n    assert 'image' in t_file, \"Images are missing\"\n    assert 'look_vec' in t_file, \"Look vector is missing\"\n    look_vec = t_file['look_vec'].value\n    assert 'path' in t_file, \"Paths are missing\"\n    print('Images found:',len(t_file['image']))\n    for _, (ikey, ival) in zip(range(1), t_file['image'].items()):\n        print('image',ikey,'shape:',ival.shape)\n        img_width, img_height = ival.shape\n    syn_image_stack = norm_stack(np.expand_dims(np.stack([a for a in t_file['image'].values()],0), -1))\n    print(syn_image_stack.shape, 'loaded')\nplt.matshow(montage2d(syn_image_stack[0:9, :, :, 0]), cmap = 'gray')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b1ae4e1ccd81185bdbc618e658ebf1cfb2913cef"},"cell_type":"code","source":"fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (10, 5))\nax1.hist(syn_image_stack[::10].ravel());\nax1.set_title('Synthetic Data')\nax2.hist(real_image_stack[::10].ravel());\nax2.set_title('Real Data')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cc0ed200245f2cb197976a8d2f499911d2448c09"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ntrain_X, test_X = train_test_split(syn_image_stack, \n                                   test_size = 0.25, \n                                   random_state = 2018)\ntrain_Y, test_Y = train_test_split(real_image_stack,\n                                   test_size = 0.25,\n                                   random_state = 2018)\nprint('Fake Images', train_X.shape, test_X.shape, train_X.max(), train_X.min(), train_X.mean(), train_X.std())\nprint('Real Images', train_Y.shape, test_Y.shape, train_Y.max(), train_Y.min(), train_Y.mean(), train_Y.std())","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4ddfb6482c13c1719db75a21763b06ba8ca59bac"},"cell_type":"markdown","source":"# Build Models"},{"metadata":{"trusted":true,"_uuid":"52957fb3dd2ae2cad78561fddf2c097d718edc9a"},"cell_type":"code","source":"from keras.layers import Input, concatenate, Conv2D, MaxPool2D, UpSampling2D, Flatten, Dense, Dropout, GaussianNoise, add, ZeroPadding2D, Cropping2D, Conv2DTranspose\nfrom keras import models, layers\nfrom collections import defaultdict\ngauss_noise_level = 1e-3\nleakiness = 0.1\ndef make_gen(depth=16, layer_count=2, use_dilation=False, use_add=False):\n    in_lay = Input(shape = (train_X.shape[1:4]), name = 'Generator_Input')\n    padding_size = ((2, 3), (2,3))\n    padding_size = ((6, 7), (4, 5))\n    gn = ZeroPadding2D(padding_size)(in_lay)\n    gn = GaussianNoise(gauss_noise_level)(gn)\n    c1 = Conv2D(depth, (3,3), padding = 'same')(gn)\n    out_layers = []\n    # dilation\n    if use_dilation:\n        for i in range(layer_count):\n            out_layers += [Conv2D(depth, (3,3), padding = 'same', dilation_rate=(2**i, 2**i))(c1)]\n            out_layers += [Conv2D(depth, (1,3), padding = 'same', dilation_rate=(1, 2**i))(c1)]\n        c2 = concatenate(out_layers)\n    else:\n        layer_db = defaultdict(lambda : [])\n        x = c1\n        layer_db[c1._keras_shape[1:3]] += [c1]\n        for i in range(layer_count):\n            x = Conv2D(depth*2**i, (3,3), padding = 'same', activation='linear')(x)\n            x = layers.BatchNormalization()(x)\n            x = layers.LeakyReLU(leakiness)(x)\n            x = MaxPool2D((2, 2))(x)\n            layer_db[x._keras_shape[1:3]] += [x]\n        for idx, i in enumerate(reversed(range(layer_count))):\n            if idx>0:\n                x = Conv2D(depth*2**i, (1,1), padding = 'same', activation='linear')(x)\n                x = layers.BatchNormalization()(x)\n                x = layers.LeakyReLU(leakiness)(x)\n            x = Conv2DTranspose(depth, (4, 4), strides = (2,2), padding = 'same')(x)\n            x = concatenate([x] + layer_db.get(x._keras_shape[1:3]))\n        c2 = x\n    \n    if use_add:\n        c_out = Conv2D(train_Y.shape[3], (1,1), padding = 'same', activation = 'tanh')(c2)\n        c_out = add([gn, c_out])\n    else:\n        c_out = Conv2D(train_Y.shape[3], (1,1), padding = 'same', activation = 'tanh')(c2)\n    c_out = Cropping2D(padding_size)(c_out)\n    \n    # try to make a grayscale downsampled image match the input well\n    ds_img_out = layers.Conv2D(1, (1, 1), strides=(1, 1), activation='tanh', padding='same')(c2)\n    ds_img_out = Cropping2D(padding_size)(ds_img_out)\n    ds_img_out = layers.AvgPool2D((2, 2), name='DS_Image')(ds_img_out)\n    \n    return models.Model(inputs = [in_lay], outputs = [c_out, ds_img_out], name = 'Generator')\n\ndef make_disc(depth=4, layer_count=3):\n    in_lay = Input(shape = (train_Y.shape[1:4]), name = 'Disc_Input')\n    gn = GaussianNoise(gauss_noise_level)(in_lay)\n    x = Conv2D(depth, (5,5), padding = 'valid', activation='linear')(gn)\n    x = layers.BatchNormalization()(x)\n    x = layers.LeakyReLU(leakiness)(x)\n    for i in range(layer_count):\n        x = Conv2D(depth*2**i, (3,3), strides=(1, 1), padding = 'same', activation='linear')(x)\n        x = layers.BatchNormalization()(x)\n        x = layers.LeakyReLU(leakiness)(x)\n        x = Conv2D(depth*2**i, (3,3), strides=(2, 2), padding = 'same', activation='linear')(x)\n        x = layers.LeakyReLU(leakiness)(x)\n    \n    c_out = layers.concatenate([layers.GlobalMaxPool2D()(x), layers.GlobalAvgPool2D()(x)])\n    c_out = Dropout(0.5)(c_out)\n    c_out = Dense(2, activation = 'softmax')(c_out)\n    return models.Model(inputs = [in_lay], outputs = [c_out], name = 'Discriminator')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"eaa1f9733dd2f432abb4265bf32e8d0923aea199"},"cell_type":"code","source":"simple_gen = make_gen(64, layer_count=3)\nsimple_disc = make_disc(32)\ndef make_full(gen_mod, disc_model):\n    raw_img_in = Input(shape = (train_X.shape[1:4]), name = 'Image_In')\n    ref_img_out, ds_img_out = simple_gen(raw_img_in)\n    ref_disc_score = simple_disc(ref_img_out)\n    return models.Model(inputs=[raw_img_in], outputs=[ref_disc_score, ds_img_out]) \nfull_gen_model = make_full(simple_gen, simple_disc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"63c270c453c38909dfc2902463b621a857426b32"},"cell_type":"code","source":"from IPython.display import Image\nfrom keras.utils.vis_utils import model_to_dot\nd = model_to_dot(simple_gen, show_shapes=True)\nd.set_rankdir('UD')\nImage(d.create_png())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f2e02b4a8bcf20442ba2c6c12d7db5eff1e1b4c5"},"cell_type":"code","source":"# show the discriminator\nImage(model_to_dot(simple_disc, show_shapes=True).create_png())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a01b12b2f128faf3c89008b44cb9cefd4a98d311"},"cell_type":"code","source":"from keras.optimizers import Adam\nBASE_LR_RATE = 1e-3\n\ndef compile_generator(lr = BASE_LR_RATE): \n    simple_disc.trainable = False\n    full_gen_model.layers[-1].set_weights(simple_disc.get_weights())\n    full_gen_model.layers[-1].trainable = False\n    full_gen_model.compile(optimizer=Adam(lr=lr), \n                           loss = ['categorical_crossentropy', 'mean_absolute_error'],\n                           loss_weights = [1, 0.5],\n                           metrics = ['accuracy'])\n\ndef compile_discriminator(lr = BASE_LR_RATE): \n    simple_disc.trainable = True\n    simple_disc.compile(optimizer=Adam(lr=lr), \n                           loss = 'categorical_crossentropy', \n                           metrics = ['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"88fffd88325e1679cb1b2685d41ba54b89319d0d"},"cell_type":"code","source":"compile_generator()\nfull_gen_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"87dc6d272fcd94eab31a7d63f58777ecab15115a"},"cell_type":"code","source":"compile_discriminator()\nsimple_disc.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"105cc4d1be9acf3318ab61944942ff7f8476f41d"},"cell_type":"code","source":"fake_score, f_img = full_gen_model.predict(train_X[0:2])\nprint(fake_score)\nplt.imshow(montage2d(f_img[:, :, :, 0]))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e922849a616c19448041a0776bbd177937aae277"},"cell_type":"markdown","source":"# Prepare Training Data"},{"metadata":{"trusted":true,"_uuid":"7c4c8ca5295a903fc419e413d99fb7da99709201"},"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\nfrom scipy.ndimage import zoom\ndg_args = dict(featurewise_center = False, \n                  samplewise_center = False,\n                  rotation_range = 5, \n                  width_shift_range = 0.1, \n                  height_shift_range = 0.1, \n                  shear_range = 0.01,\n                  zoom_range = [0.8, 1.2],  \n                  horizontal_flip = True, \n                  vertical_flip = False,\n                  fill_mode = 'reflect',\n               data_format = 'channels_last')\n\nimage_gen = ImageDataGenerator(**dg_args)\ndef make_train_gen_batch(in_X, batch_size = 512):\n    # improve generator\n    for x in image_gen.flow(in_X, batch_size=batch_size):\n        out_vec = np.zeros((x.shape[0], 2))\n        out_vec[:, 1] = 1.0\n        yield x, [out_vec, zoom(x, [1, 1/2.05, 1/2.05, 1], order=1)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c85ede33ba484dc6dfc9c5bf396e50cc5f0a1291"},"cell_type":"code","source":"gen_train = make_train_gen_batch(train_X)\ngen_valid = make_train_gen_batch(test_X)\na, (b, c) = next(gen_train)\nprint(a.shape, b.shape, c.shape)\nfig, (ax1) = plt.subplots(1, 1, figsize = (20, 10))\nax1.imshow(montage2d(a[:, :, :, 0]), cmap = 'bone')\nax1.set_title('Synth Images')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0f5cf5307ef966a506806307ce8c874b0f9eedd0"},"cell_type":"code","source":"def show_status(seed = None, img_cnt = 9):\n    if seed is not None:\n        np.random.seed(seed)\n    syn_block = np.random.permutation(syn_image_stack)[0:img_cnt]\n    real_block = np.random.permutation(real_image_stack)[0:img_cnt]\n    bins = np.linspace(-1, 1, 30)\n    fig, ((ax1, ax2, ax3), (ax1h, ax2h, ax3h))  = plt.subplots(2, 3, figsize = (24, 12))\n    ax1.imshow(montage2d(syn_block[:, :, :, 0]), cmap = 'gray')\n    ax1h.hist(syn_block[:, :, :, 0].flatten(), bins)\n    ax1.set_title('Simulated Images')\n    gen_stack, _ = simple_gen.predict(syn_block)\n    ax2.imshow(montage_rgb(gen_stack[: , :, :]))\n    ax2h.hist(gen_stack[:, :, :, 0].flatten(), bins)\n    ax2.set_title('Generated Images\\nReal: %2.2f%%' % (np.mean(simple_disc.predict(gen_stack)[:, 1])*100))\n    ax3.imshow(montage_rgb(real_block[:, :, :]))\n    ax3h.hist(real_block[:, :, :, 0].flatten(), bins)\n    ax3.set_title('Real Images\\nReal: %2.2f%%' % (np.mean(simple_disc.predict(real_block)[:, 1])*100))\n    return fig\nshow_status();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f99da15ad8297f6a0d0d7174e69026f3ff4ca3ce"},"cell_type":"code","source":"def make_train_disc_batch(in_fake, in_real, batch_size = 256, refine_images=True):\n    \"\"\"we create batches consisting of a 50/50 split between\n    fake and real images. The fake images are processed using the refiner (refine_images=True), but\n    in future we plan to provide fake images from many different generations of\n    the generator model to 'stabilize training'  \"\"\"\n    while True:\n        real_img = image_gen.flow(in_real, batch_size=batch_size)\n        fake_img = image_gen.flow(in_fake, batch_size=batch_size)\n        for (c_real, c_fake) in zip(real_img, fake_img):\n            real_cat = np.zeros((c_real.shape[0], 2))\n            real_cat[:, 1] = 1.0 # real\n            refined_cat = np.zeros((c_fake.shape[0], 2))\n            refined_cat[:, 0] = 1.0 # learn that they are fake\n\n            if refine_images:\n                c_refined, _ = simple_gen.predict(c_fake)\n            else:\n                c_fake = c_fake\n            yield np.concatenate([c_real, c_refined], 0), np.concatenate([real_cat, refined_cat])\ndisc_train = make_train_disc_batch(train_X, train_Y)\ndisc_valid = make_train_disc_batch(test_X, test_Y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"acf2f941a6c0da4ce1f35557ea48d4a8be1191a5"},"cell_type":"code","source":"compile_discriminator()\nprint('Improving Discriminator')\nsimple_disc.fit_generator(disc_train, steps_per_epoch=100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d1ca7d85756ae884ce32bab87762d00311a60757"},"cell_type":"code","source":"compile_generator()\nprint('Improving Generator')\nfull_gen_model.fit_generator(gen_train, steps_per_epoch=200)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"75df94f7f8f33482a938ffc1719a1603f116404b"},"cell_type":"code","source":"show_status(2002, 25).savefig('pretraining_image_gen.png', dpi = 300)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ce4a0619caa77031af588c9d4963cfe43e148b12"},"cell_type":"markdown","source":"# Big Training\nHere we run a number of loops \n- improve the generator\n- improve the discriminator\n- decrease the learning rate of both\n- show results on fixed images\n- repeat"},{"metadata":{"trusted":true,"_uuid":"be47f409b3f48c24c3efbbd3f47b5d32e1360e3d","scrolled":false},"cell_type":"code","source":"from IPython.display import clear_output, display\nt_steps = 25\nm_epochs = 2\nv_steps = 0\nepochs = 25\ntrain_history = []\nfrom keras.callbacks import EarlyStopping\nes_callback = lambda : EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=1)\nfor i in range(epochs):\n    cur_lr = BASE_LR_RATE*(0.8**(i))\n    # we might be required to precompute images at some point here\n    disc_train = make_train_disc_batch(train_X, train_Y)\n    disc_valid = make_train_disc_batch(test_X, test_Y)\n    compile_discriminator(cur_lr)\n    print('Improving Discriminator')\n    if v_steps>0:\n        v_args = dict(validation_data=disc_valid, validation_steps=v_steps)\n    else:\n        v_args = {}\n    train_history+=[\n        simple_disc.fit_generator(disc_train, steps_per_epoch=t_steps, epochs=m_epochs, **v_args)\n    ]\n    \n    plt.close('all')\n    clear_output()\n    display(show_status(2018, 9))\n    \n    print('Improving Generator ({:2.2g})'.format(cur_lr))\n    compile_generator(cur_lr)\n    if v_steps>0:\n        v_args = dict(validation_data=gen_valid, validation_steps=v_steps)\n    else:\n        v_args = {}\n    train_history+=[\n        full_gen_model.fit_generator(gen_train, \n                                 steps_per_epoch=t_steps, epochs=m_epochs, **v_args)\n    ]\n    display(show_status(2018, 9))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"528b2ed142a64927ae1fc58c9992922625c16eee"},"cell_type":"code","source":"from itertools import chain\ncomb_hist = [(np.ones((len(h.history['loss']),)), \n              np.power(-1*np.ones((len(h.history['loss']),)),i), \n              h.history['loss']) for i, h in enumerate(train_history)]\nepoch_vec = np.cumsum(list(chain(*[a for a, b, c in comb_hist])))\ncycle_vec = np.array(list(chain(*[b for a, b, c in comb_hist])))\nloss_vec = np.array(list(chain(*[c for a, b, c in comb_hist])))\nfig, (ax1) = plt.subplots(1, 1, figsize=(6, 3))\nax1.semilogy(epoch_vec, loss_vec)\nax1.semilogy(epoch_vec[cycle_vec==-1], loss_vec[cycle_vec==-1], 'r+', label='Generator')\nax1.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"246082aa5030aeb922acb05f5b652cb433cf1acd"},"cell_type":"code","source":"show_status(2002, 25).savefig('image_gen.png', dpi = 300)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"743785c2f499aa1c033241684c424142684b7aa8"},"cell_type":"code","source":"show_status(2003, 25);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3236199c8377e75fc0bd7dc9d36e2a7965cc53c4"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}